{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment 2 CSCN8000 Artificial Intelligence Algorithms and Mathematics\n",
    "\n",
    "1.Consider the heart disease dataset in pandas dataframe 2.Remove outliers using mean,median,Z score. 3.Convert text columns to numbers using label encoding and one hot encoding 4.Apply scaling 5.Build a machine learning classification model using support vector machine. Demonstrate the standalone model as well as Bagging model and include observations about the oerformance 6.Now use decision tree classifier. Use standalone model as well as Bagging and check if you notice any difference in performance 7.Comparing performance of svm and decision tree classifier figure out where it makes most sense to use bagging and why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll take the following actions to complete these tasks:\n",
    "\n",
    "1: Load the heart disease dataset into a pandas DataFrame after importing the required libraries.\n",
    "\n",
    "2: Use the mean, median, and Z-score techniques to eliminate outliers.\n",
    "\n",
    "3: Use label encoding and one-hot encoding to convert text columns to numbers.\n",
    "\n",
    "4: To the numerical columns, apply scaling.\n",
    "\n",
    "5: Utilise Support Vector Machine (SVM) to create a machine learning classification model.\n",
    "\n",
    "6: Create a decision tree classification model using machine learning.\n",
    "\n",
    "7: To determine the situations when using Bagging is most appropriate, compare the performance of SVM and Decision Tree Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Import the necessary libraries and load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age Sex ChestPainType  RestingBP  Cholesterol  FastingBS RestingECG  MaxHR  \\\n",
      "0   40   M           ATA        140          289          0     Normal    172   \n",
      "1   49   F           NAP        160          180          0     Normal    156   \n",
      "2   37   M           ATA        130          283          0         ST     98   \n",
      "3   48   F           ASY        138          214          0     Normal    108   \n",
      "4   54   M           NAP        150          195          0     Normal    122   \n",
      "\n",
      "  ExerciseAngina  Oldpeak ST_Slope  HeartDisease  \n",
      "0              N      0.0       Up             0  \n",
      "1              N      1.0     Flat             1  \n",
      "2              N      0.0       Up             0  \n",
      "3              Y      1.5     Flat             1  \n",
      "4              N      0.0       Up             0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset from the CSV file\n",
    "df = pd.read_csv(r\"C:\\Users\\asus\\Downloads\\archive (1).zip\")\n",
    "\n",
    "# Let's check the first few rows of the dataset\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Remove outliers using different methods like mean, median, and Z-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Shape: (918, 12)\n",
      "Shape after mean method: (753, 12)\n",
      "Shape after median method: (690, 12)\n",
      "Shape after Z-score method: (899, 12)\n"
     ]
    }
   ],
   "source": [
    "def remove_outliers_mean(df, columns):\n",
    "    for column in columns:\n",
    "        mean = df[column].mean()\n",
    "        std = df[column].std()\n",
    "        df = df[(df[column] > mean - 2 * std) & (df[column] < mean + 2 * std)]\n",
    "    return df\n",
    "\n",
    "def remove_outliers_median(df, columns):\n",
    "    for column in columns:\n",
    "        median = df[column].median()\n",
    "        q1 = df[column].quantile(0.25)\n",
    "        q3 = df[column].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        lower_bound = q1 - 1.5 * iqr\n",
    "        upper_bound = q3 + 1.5 * iqr\n",
    "        df = df[(df[column] > lower_bound) & (df[column] < upper_bound)]\n",
    "    return df\n",
    "\n",
    "def remove_outliers_zscore(df, columns, threshold=3):\n",
    "    for column in columns:\n",
    "        z_scores = (df[column] - df[column].mean()) / df[column].std()\n",
    "        df = df[abs(z_scores) < threshold]\n",
    "    return df\n",
    "\n",
    "# Columns for which outliers need to be removed (numerical columns only)\n",
    "numerical_columns = [\"Age\", \"RestingBP\", \"Cholesterol\", \"MaxHR\", \"Oldpeak\"]\n",
    "\n",
    "# Remove outliers using mean, median, and Z-score methods\n",
    "df_mean = remove_outliers_mean(df, numerical_columns)\n",
    "df_median = remove_outliers_median(df, numerical_columns)\n",
    "df_zscore = remove_outliers_zscore(df, numerical_columns)\n",
    "\n",
    "# Let's check the shape of the dataframes after removing outliers using different methods\n",
    "print(\"Original Shape:\", df.shape)\n",
    "print(\"Shape after mean method:\", df_mean.shape)\n",
    "print(\"Shape after median method:\", df_median.shape)\n",
    "print(\"Shape after Z-score method:\", df_zscore.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Convert text columns to numbers using  different encodings :label encoding and one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age  Sex  RestingBP  Cholesterol  FastingBS  MaxHR  ExerciseAngina  \\\n",
      "0   40    1        140          289          0    172               0   \n",
      "1   49    0        160          180          0    156               0   \n",
      "2   37    1        130          283          0     98               0   \n",
      "3   48    0        138          214          0    108               1   \n",
      "4   54    1        150          195          0    122               0   \n",
      "\n",
      "   Oldpeak  HeartDisease  ChestPainType_0  ChestPainType_1  ChestPainType_2  \\\n",
      "0      0.0             0            False             True            False   \n",
      "1      1.0             1            False            False             True   \n",
      "2      0.0             0            False             True            False   \n",
      "3      1.5             1             True            False            False   \n",
      "4      0.0             0            False            False             True   \n",
      "\n",
      "   ChestPainType_3  RestingECG_0  RestingECG_1  RestingECG_2  ST_Slope_0  \\\n",
      "0            False         False          True         False       False   \n",
      "1            False         False          True         False       False   \n",
      "2            False         False         False          True       False   \n",
      "3            False         False          True         False       False   \n",
      "4            False         False          True         False       False   \n",
      "\n",
      "   ST_Slope_1  ST_Slope_2  \n",
      "0       False        True  \n",
      "1        True       False  \n",
      "2       False        True  \n",
      "3        True       False  \n",
      "4       False        True  \n"
     ]
    }
   ],
   "source": [
    "# Convert categorical columns using label encoding\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"Sex\"] = label_encoder.fit_transform(df[\"Sex\"])\n",
    "df[\"ChestPainType\"] = label_encoder.fit_transform(df[\"ChestPainType\"])\n",
    "df[\"FastingBS\"] = label_encoder.fit_transform(df[\"FastingBS\"])\n",
    "df[\"RestingECG\"] = label_encoder.fit_transform(df[\"RestingECG\"])\n",
    "df[\"ExerciseAngina\"] = label_encoder.fit_transform(df[\"ExerciseAngina\"])\n",
    "df[\"ST_Slope\"] = label_encoder.fit_transform(df[\"ST_Slope\"])\n",
    "\n",
    "# Convert categorical columns using one-hot encoding\n",
    "df_one_hot = pd.get_dummies(df, columns=[\"ChestPainType\", \"RestingECG\", \"ST_Slope\"])\n",
    "\n",
    "# Let's check the modified dataframe with one-hot encoding\n",
    "print(df_one_hot.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Apply scaling to the numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the features (X) and target (y)\n",
    "X = df_one_hot.drop(\"HeartDisease\", axis=1)\n",
    "y = df_one_hot[\"HeartDisease\"]\n",
    "\n",
    "# Apply scaling to numerical columns using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5:Build a machine learning classification model using support vector machine. Demonstrate the standalone model as well as Bagging model and include observations about the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of standalone SVM model: 0.8586956521739131\n",
      "Accuracy of SVM Bagging model: 0.8478260869565217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build and train the standalone SVM model\n",
    "svm_model_standalone = SVC(kernel=\"linear\", random_state=42)\n",
    "svm_model_standalone.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set for the standalone model\n",
    "y_pred_svm_standalone = svm_model_standalone.predict(X_test)\n",
    "\n",
    "# Calculate accuracy for the standalone SVM model\n",
    "accuracy_svm_standalone = accuracy_score(y_test, y_pred_svm_standalone)\n",
    "print(\"Accuracy of standalone SVM model:\", accuracy_svm_standalone)\n",
    "\n",
    "# Build and train the Bagging model using SVM as the base estimator\n",
    "svm_model_bagging = BaggingClassifier(base_estimator=SVC(kernel=\"linear\"), n_estimators=10, random_state=42)\n",
    "svm_model_bagging.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set for the Bagging model\n",
    "y_pred_svm_bagging = svm_model_bagging.predict(X_test)\n",
    "\n",
    "# Calculate accuracy for the Bagging model\n",
    "accuracy_svm_bagging = accuracy_score(y_test, y_pred_svm_bagging)\n",
    "print(\"Accuracy of SVM Bagging model:\", accuracy_svm_bagging)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the standalone SVM model will vary depending on the particular dataset and issue at hand. SVMs work well for classification jobs in general, especially when the data is well-separated and there is a distinct difference between the classes.\n",
    "\n",
    "When the dataset is noisy or contains outliers, bagging using SVM as the base estimator can increase the model's resilience and generalisation performance. By averaging the forecasts from various SVM models, it lowers variance and overfitting.\n",
    "\n",
    "It's possible that the Bagging model performs better than the single SVM model. The complexity of the underlying link between the features and the target variable will depend on the dataset.\n",
    "\n",
    "In situations where the base estimator is unstable or prone to overfitting, bagging often enhances performance. The improvement from Bagging may not be significant in this particular instance because SVMs are typically steady.\n",
    "\n",
    "When the performance of the standalone SVM model is subpar or the dataset is limited and very variable, the effectiveness of Bagging may become more apparent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6: Build the Decision Tree Classifier models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of standalone Decision Tree model: 0.8097826086956522\n",
      "Accuracy of Decision Tree Bagging model: 0.8641304347826086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Build and train the standalone Decision Tree Classifier model\n",
    "dt_model_standalone = DecisionTreeClassifier(random_state=42)\n",
    "dt_model_standalone.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set for the standalone Decision Tree model\n",
    "y_pred_dt_standalone = dt_model_standalone.predict(X_test)\n",
    "\n",
    "# Calculate accuracy for the standalone Decision Tree model\n",
    "accuracy_dt_standalone = accuracy_score(y_test, y_pred_dt_standalone)\n",
    "print(\"Accuracy of standalone Decision Tree model:\", accuracy_dt_standalone)\n",
    "\n",
    "# Build and train the Bagging model using Decision Tree Classifier as the base estimator\n",
    "dt_model_bagging = BaggingClassifier(base_estimator=DecisionTreeClassifier(random_state=42), n_estimators=10, random_state=42)\n",
    "dt_model_bagging.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set for the Bagging model\n",
    "y_pred_dt_bagging = dt_model_bagging.predict(X_test)\n",
    "\n",
    "# Calculate accuracy for the Bagging model\n",
    "accuracy_dt_bagging = accuracy_score(y_test, y_pred_dt_bagging)\n",
    "print(\"Accuracy of Decision Tree Bagging model:\", accuracy_dt_bagging)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 7: Analysing the performance of the Decision Tree Classifier and SVM to determine when and why Bagging is most appropriate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of standalone SVM model: 0.8586956521739131\n",
      "Accuracy of SVM Bagging model: 0.8478260869565217\n",
      "Accuracy of standalone Decision Tree model: 0.8097826086956522\n",
      "Accuracy of Decision Tree Bagging model: 0.8641304347826086\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of standalone SVM model:\", accuracy_svm_standalone)\n",
    "print(\"Accuracy of SVM Bagging model:\", accuracy_svm_bagging)\n",
    "print(\"Accuracy of standalone Decision Tree model:\", accuracy_dt_standalone)\n",
    "print(\"Accuracy of Decision Tree Bagging model:\", accuracy_dt_bagging)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the independent models:\n",
    "\n",
    "SVM: The accuracy_svm_standalone variable represents the accuracy of the standalone SVM model.\n",
    "Decision Tree Classifier: accuracy_dt_standalone represents the accuracy of the standalone Decision Tree model.\n",
    "The Bagging models are contrasted:\n",
    "\n",
    "SVM Bagging: accuracy_svm_bagging is a representation of the accuracy of the Bagging model using SVM as the basis estimator.\n",
    "Decision Tree Bagging: accuracy_dt_bagging is a representation of the accuracy of the Bagging model using the Decision Tree Classifier as the base estimator.\n",
    "The exact dataset and the underlying link between features and the target variable will determine how well SVM and Decision Tree Classifier (standalone and Bagging) perform.\n",
    "\n",
    "SVM generally works well with high-dimensional data and nonlinear decision boundaries. Complex interactions between features and labels can be handled by it.\n",
    "\n",
    "A straightforward and understandable model that can handle both categorical and numerical features is the decision tree classifier. However, especially with deep trees, it could suffer from overfitting.\n",
    "\n",
    "By combining many instances of the base model, bagging reduces overfitting and enhances generalisation. When the base model, such as Decision Tree Classifier, is prone to overfitting, it might be more advantageous.\n",
    "\n",
    "When the performance of the standalone model is poor or the dataset is limited and highly variable, the benefits of bagging become more apparent.\n",
    "\n",
    "By considering the performance comparison between SVM and Decision Tree Classifier, it may not be necessary to combine Bagging with SVM if SVM achieves a greater accuracy than the Decision Tree model (either standalone or with Bagging).\n",
    "\n",
    "Applying Bagging to the Decision Tree, however, may greatly enhance its performance if the standalone Decision Tree Classifier performs less accurately than SVM or exhibits overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

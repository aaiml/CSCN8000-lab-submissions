{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3\n",
    "# Zohair Mubasheer Ahmed\n",
    "# 8897082"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Assignment 3 CSCN8000 Artificial Intelligence Algorithms and Mathematics**\n",
    "\n",
    "1.  Use iris flower dataset from sklearn library and try to form clusters of flowers using petal width and length features. Drop the other two features for simplicity.\n",
    "   \n",
    "    Figure out if any preprocessing such as scaling would help here\n",
    "    \n",
    "    Draw elbow plot and from that figure out optimal value of k\n",
    "    \n",
    "2.  Use the heart dataset from the Resources Folder or access it from https://www.kaggle.com/fedesoriano/heart-failure-prediction \n",
    "   \n",
    "    Load heart disease dataset in pandas dataframe\n",
    "   \n",
    "    Remove outliers using Z score. Usual guideline is to remove anything that has Z score > 3 formula or Z score < -3\n",
    "    \n",
    "    Convert text columns to numbers using label encoding / one hot encoding\n",
    "    \n",
    "    Apply scaling\n",
    "    \n",
    "    Build a classification model using various methods (SVM, logistic regression, random forest) and check which model gives you the best accuracy\n",
    "    \n",
    "    Now use PCA to reduce dimensions, retrain your model and see its impact on your model in terms of accuracy. \n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "**Notes: This lab should be submitted as a notebook and an HTML. Follow https://docs.github.com/en/pages/quickstart.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Load the Iris dataset\n",
    "data = load_iris()\n",
    "X = data.data[:, 2:4]  # Using only petal width and length\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Elbow plot to find optimal value of k\n",
    "inertia = []\n",
    "for k in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "    kmeans.fit(X_scaled)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, 11), inertia, marker='o')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Plot for KMeans')\n",
    "plt.show()\n",
    "\n",
    "# From the elbow plot, it looks like the optimal value of k is 3\n",
    "\n",
    "# Fit KMeans with optimal k\n",
    "optimal_k = 3\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=0)\n",
    "clusters = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# Visualize the clusters\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=clusters, cmap='viridis')\n",
    "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=300, c='red', marker='X', label='Centroids')\n",
    "plt.xlabel('Petal Width')\n",
    "plt.ylabel('Petal Length')\n",
    "plt.title('Clustered Iris Flowers')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# # Load heart disease dataset\n",
    "# heart_data = pd.read_csv(\"heart.csv\")  \n",
    "\n",
    "# # Removing outliers using Z-score\n",
    "# z_scores = np.abs((heart_data - heart_data.mean()) / heart_data.std())\n",
    "# heart_data_no_outliers = heart_data[(z_scores < 3).all(axis=1)]\n",
    "\n",
    "# # Convert text columns to numbers using label encoding\n",
    "# label_encoder = LabelEncoder()\n",
    "# heart_data_no_outliers['sex'] = label_encoder.fit_transform(heart_data_no_outliers['sex'])\n",
    "# heart_data_no_outliers['cp'] = label_encoder.fit_transform(heart_data_no_outliers['cp'])\n",
    "\n",
    "# # Split data into features and target\n",
    "# X = heart_data_no_outliers.drop('target', axis=1)\n",
    "# y = heart_data_no_outliers['target']\n",
    "\n",
    "# # Apply scaling\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# # Split data into train and test sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# # Build classification models\n",
    "# svm_model = SVC(random_state=0)\n",
    "# logreg_model = LogisticRegression(random_state=0)\n",
    "# rf_model = RandomForestClassifier(random_state=0)\n",
    "\n",
    "# # Train models\n",
    "# svm_model.fit(X_train, y_train)\n",
    "# logreg_model.fit(X_train, y_train)\n",
    "# rf_model.fit(X_train, y_train)\n",
    "\n",
    "# # Predict and evaluate models\n",
    "# svm_preds = svm_model.predict(X_test)\n",
    "# logreg_preds = logreg_model.predict(X_test)\n",
    "# rf_preds = rf_model.predict(X_test)\n",
    "\n",
    "# print(\"SVM Accuracy:\", accuracy_score(y_test, svm_preds))\n",
    "# print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, logreg_preds))\n",
    "# print(\"Random Forest Accuracy:\", accuracy_score(y_test, rf_preds))\n",
    "\n",
    "# # Applying PCA for dimensionality reduction\n",
    "# pca = PCA(n_components=5)\n",
    "# X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# # Split PCA-transformed data\n",
    "# X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(X_pca, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# # Retrain models with PCA-transformed data\n",
    "# svm_model.fit(X_train_pca, y_train_pca)\n",
    "# logreg_model.fit(X_train_pca, y_train_pca)\n",
    "# rf_model.fit(X_train_pca, y_train_pca)\n",
    "\n",
    "# # Predict and evaluate models with PCA-transformed data\n",
    "# svm_preds_pca = svm_model.predict(X_test_pca)\n",
    "# logreg_preds_pca = logreg_model.predict(X_test_pca)\n",
    "# rf_preds_pca = rf_model.predict(X_test_pca)\n",
    "\n",
    "# print(\"SVM Accuracy with PCA:\", accuracy_score(y_test_pca, svm_preds_pca))\n",
    "# print(\"Logistic Regression Accuracy with PCA:\", accuracy_score(y_test_pca, logreg_preds_pca))\n",
    "# print(\"Random Forest Accuracy with PCA:\", accuracy_score(y_test_pca, rf_preds_pca))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load heart disease dataset\n",
    "df = pd.read_csv(\"heart.csv\")  \n",
    "\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Calculate the z-scores for the numeric columns\n",
    "z_scores = zscore(df[['Age', 'RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']])\n",
    "\n",
    "# Keep rows where z-scores are within [-3, 3]\n",
    "df_cleaned = df[(z_scores > -3).all(axis=1) & (z_scores < 3).all(axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoders = {}\n",
    "categorical_columns = ['Sex', 'ChestPainType', 'FastingBS', 'RestingECG', 'ExerciseAngina', 'ST_Slope']\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    df_cleaned[col] = le.fit_transform(df_cleaned[col])\n",
    "    label_encoders[col] = le\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoders = {}\n",
    "categorical_columns = ['Sex', 'ChestPainType', 'FastingBS', 'RestingECG', 'ExerciseAngina', 'ST_Slope']\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    df_cleaned[col] = le.fit_transform(df_cleaned[col])\n",
    "    label_encoders[col] = le\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(df_cleaned[['Age', 'RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']])\n",
    "df_scaled = pd.DataFrame(scaled_features, columns=['Age', 'RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak'])\n",
    "df_scaled = pd.concat([df_scaled, df_cleaned.drop(['Age', 'RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak'], axis=1)], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X = df_scaled.drop('HeartDisease', axis=1)\n",
    "y = df_scaled['HeartDisease']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'SVM': SVC(),\n",
    "    'Random Forest': RandomForestClassifier()\n",
    "}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'{model_name} Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train_pca, y_train)\n",
    "    y_pred = model.predict(X_test_pca)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'{model_name} Accuracy with PCA: {accuracy}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiml_math_class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
